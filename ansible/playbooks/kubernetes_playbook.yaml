- name: Host file update - Local DNS setup across all the servers
  hosts: 
  - aws_ec2_workers
  - aws_ec2_master

  gather_facts: true
  become: true
  tasks:
  - name: Update the /etc/hosts file with node name
    tags: etchostsupdate
    become: true
    become_user: root
    lineinfile:
      path: "/etc/hosts"
      regexp: ".*\t{{ hostvars[item]['ansible_hostname']}}\t{{ hostvars[item]['ansible_hostname']}}"
      line: "{{ hostvars[item]['ansible_env'].SSH_CONNECTION.split(' ')[2] }}\t{{ hostvars[item]['ansible_hostname']}}\t{{ hostvars[item]['ansible_hostname']}}"
      state: present
      backup: true
    register: etchostsupdate
    when: ansible_hostname != "{{ item }}" or ansible_hostname == "{{ item }}"
    with_items: 
      - "{{groups['aws_ec2_workers']}}"
      - "{{groups['aws_ec2_master']}}"

- hosts: 
   - aws_ec2_master
   - aws_ec2_workers
  become: true
  gather_facts: true

  tasks:
     - name: Create containerd config file
       file:
         path: "/etc/modules-load.d/k8s.conf"
         state: "touch"

     - name: Add conf for containerd
       blockinfile:
         path: "/etc/modules-load.d/k8s.conf"
         block: |
               overlay
               br_netfilter

     - name: modprobe
       shell: |
               sudo modprobe overlay
               sudo modprobe br_netfilter
     - name: Set system configurations for Kubernetes networking
       file:
         path: "/etc/sysctl.d/k8s.conf"
         state: "touch"

     - name: Add conf for containerd
       blockinfile:
         path: "/etc/sysctl.d/k8s.conf"
         block: |
                net.bridge.bridge-nf-call-iptables = 1
                net.ipv4.ip_forward = 1
                net.bridge.bridge-nf-call-ip6tables = 1

     - name: Apply new settings
       command: sudo sysctl --system

     - name: install containerd
       shell: |
               sudo apt-get update
               sudo apt-get install -y ca-certificates curl gnupg lsb-release apt-transport-https
               sudo mkdir -m 0755 -p /etc/apt/keyrings
               curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

     - name: Set up the repository
       shell: |
               echo \
               "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
               $(lsb_release -cs) stable" | 
               sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
               sudo apt-get update
     
     - name: Install Docker Engine, containerd, and Docker Compose
       shell: |
               VERSION_STRING=5:23.0.1-1~ubuntu.20.04~focal
               sudo apt-get install -y docker-ce=$VERSION_STRING docker-ce-cli=$VERSION_STRING containerd.io docker-buildx-plugin docker-compose-plugin   
               sudo usermod -aG docker $USER
               sudo sed -i 's/disabled_plugins/#disabled_plugins/' /etc/containerd/config.toml
     
     - name: Restart containerd
       shell: |
               sudo systemctl restart containerd
               sudo swapoff -a   

     - name: On all nodes, install kubeadm, kubelet, and kubectl
       shell: |
               curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
               cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
               deb https://apt.kubernetes.io/ kubernetes-xenial main
               EOF
               sudo apt-get update && sudo apt-get install -y kubelet=1.27.0-00 kubeadm=1.27.0-00 kubectl=1.27.0-00
               sudo apt-mark hold kubelet kubeadm kubectl 

- hosts: "aws_ec2_master"
  become: true
  gather_facts: true
  tasks:
     - name: On the control plane set up kubectl access
       shell: |
               sudo kubeadm init --pod-network-cidr 172.31.0.0/16 --kubernetes-version 1.27.0
               mkdir -p $HOME/.kube
               sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
               sudo chown $(id -u):$(id -g) $HOME/.kube/config

     - name: Verify the cluster is working
       shell: |
               kubectl get nodes
               kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.0/manifests/calico.yaml
               kubeadm token create --print-join-command
               sudo kubeadm join ...
               kubectl get nodes

- hosts: aws_ec2_master
  become: true
  gather_facts: true
  tasks:
    - name: Getting the joing command and storing into VAR
      command: "sudo kubeadm token create --print-join-command"
      register: command_output
    - set_fact:
       string_to_echo: "{{ command_output.stdout }}"
    - name: Verifying var string output
      debug: 
        msg: "{{string_to_echo}}"

- hosts: aws_ec2_workers
  become: true
  gather_facts: true
  tasks:
    - name: Importing and Extracting kubernetes output join request (var) from aws_ec2_master group
      set_fact:
        map_var: "{{groups['aws_ec2_master'] | map('extract',hostvars,'string_to_echo') | list }}"
    - name: Converting map to My String var
      set_fact:
        my_string: "{{ map_var | join(',') }}"
    - name: verifying string output
      debug: 
        msg: "{{my_string }}"
    - name: Apply command to register workers Nodes into Kubernetes CLuster
      command: "{{my_string}}"